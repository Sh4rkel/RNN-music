{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "RNN for music generation",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T18:42:27.024078Z",
     "start_time": "2024-08-12T18:42:25.164652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T18:42:38.118649Z",
     "start_time": "2024-08-12T18:42:38.107555Z"
    }
   },
   "cell_type": "code",
   "source": "torch.manual_seed(72)",
   "id": "2d9c7f6977d4b367",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x217f298ead0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T18:48:10.853953Z",
     "start_time": "2024-08-12T18:48:10.848473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MusicRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(MusicRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size))"
   ],
   "id": "3549f33f26d2c022",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T18:50:27.781519Z",
     "start_time": "2024-08-12T18:50:27.775132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_size = 8 \n",
    "hidden_size = 72\n",
    "output_size = 8\n",
    "num_layers = 4\n",
    "sequence_length = 16\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01"
   ],
   "id": "ca35891f58104bb2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T18:52:02.934644Z",
     "start_time": "2024-08-12T18:52:02.929680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dummy_data(num_sequences):\n",
    "    data = []\n",
    "    for _ in range(num_sequences):\n",
    "        seq = np.random.randint(0, input_size, size = sequence_length)\n",
    "        data.append(seq)\n",
    "    return np.array(data)"
   ],
   "id": "cd0155ec63c61c4c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:20:33.982724Z",
     "start_time": "2024-08-12T19:20:33.975146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = create_dummy_data(100)\n",
    "train_data = torch.LongTensor(train_data)"
   ],
   "id": "2e79c35ccaad72ea",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T18:53:59.042367Z",
     "start_time": "2024-08-12T18:53:57.840044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MusicRNN(input_size, hidden_size, output_size, num_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ],
   "id": "71323883f3f176af",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:20:47.360303Z",
     "start_time": "2024-08-12T19:20:37.673642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    for i in range(0, len(train_data) - batch_size, batch_size):\n",
    "        batch = train_data[i : i + batch_size]\n",
    "        inputs = nn.functional.one_hot(batch[:, : - 1], num_classes = input_size).float()\n",
    "        targets = batch[:, 1:]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs, hidden = model(inputs, hidden)\n",
    "        \n",
    "        hidden = tuple(h.detach() for h in hidden)\n",
    "        \n",
    "        outputs = outputs.reshape(-1, input_size)\n",
    "        targets = targets.reshape(-1)\n",
    "        \n",
    "        loss = criterion(outputs.view(-1, input_size), targets.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        avg_loss = total_loss / (len(train_data) // batch_size)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')"
   ],
   "id": "2d41e468216158e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Average Loss: 2.0781\n",
      "Epoch [20/100], Average Loss: 2.0781\n",
      "Epoch [30/100], Average Loss: 2.0781\n",
      "Epoch [40/100], Average Loss: 2.0781\n",
      "Epoch [50/100], Average Loss: 2.0781\n",
      "Epoch [60/100], Average Loss: 2.0781\n",
      "Epoch [70/100], Average Loss: 2.0781\n",
      "Epoch [80/100], Average Loss: 2.0781\n",
      "Epoch [90/100], Average Loss: 2.0781\n",
      "Epoch [100/100], Average Loss: 2.0779\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:20:55.830861Z",
     "start_time": "2024-08-12T19:20:55.757808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generated_music(model, seed, length):\n",
    "    with torch.no_grad():\n",
    "        current_seq = torch.LongTensor(seed).unsqueeze(0)\n",
    "        hidden = model.init_hidden(1)\n",
    "        generated = list(seed)\n",
    "        \n",
    "        for _ in range(length):\n",
    "            input_seq = nn.functional.one_hot(current_seq, num_classes=input_size).float()\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "            probabilities = nn.functional.softmax(output[0, -1], dim=0)\n",
    "            next_note = torch.multinomial(probabilities, 1).item()\n",
    "            generated.append(next_note)\n",
    "            current_seq = torch.LongTensor([next_note]).unsqueeze(0)\n",
    "    \n",
    "    return generated\n",
    "\n",
    "seed = [0, 1, 2, 3]\n",
    "music = generated_music(model, seed, 50)\n",
    "print(\"Generated melody:\", music)"
   ],
   "id": "2f2b77e8638661b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated melody: [0, 1, 2, 3, 5, 0, 5, 5, 3, 1, 6, 4, 6, 3, 3, 5, 7, 0, 7, 0, 7, 6, 0, 2, 2, 7, 6, 1, 5, 2, 7, 7, 7, 6, 6, 5, 6, 2, 4, 2, 3, 7, 2, 5, 6, 0, 1, 3, 6, 6, 1, 1, 3, 0]\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
